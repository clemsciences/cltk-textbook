{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominant-celebration",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <center>Commencer à utiliser CLTK</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-citation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<center>Avril 2022</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-france",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Abordé dans ce chapitre"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dans ce chapitre, vous allez apprendre à : \n",
    "- récupérer un texte,\n",
    "- comprendre les notions de *pipeline* de traitement, de document CLTK ou `Doc`, \n",
    "- utiliser un *pipeline* de traitement sur un texte,\n",
    "- manipuler un texte au niveau du mot et aussi au niveau de la phrase."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Récupérer un texte"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bien que CLTK permette de récupérer des corpus de textes pour chaque langue, nous allons commencer par traiter des données stockées en local. Nous pouvons retrouver ce qu'on va faire dans <a href=\"https://github.com/cltk/cltk/blob/master/notebooks/CLTK%20Demonstration.ipynb\">le *notebook* sur le dépôt de CLTK</a>. Dans le dépôt actuel, nous mettons à disposition une collection de textes.\n",
    "Regardons un extrait de Tite-Live.\n",
    "\n",
    "Tout d'abord, nous avons besoin de récupérer le texte en le stockant dans une variable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"texts/lat-livy.txt\") as f:\n",
    "    livy_full = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Excellent ! Maintenant, regardons ce que nous avons en main."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Extrait du texte :\", livy_full[:200])\n",
    "print(\"Nombre de caractères :\", len(livy_full))\n",
    "print(\"Nombre approximatif de token :\", len(livy_full.split()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous utilisons l'expression \"nombre approximatif de tokens\" parce que les tokens sont considérés comme quelque chose qui a une fonction syntaxique dans le texte. Cela signifie qu'un token n'est pas seulement un mot, mais aussi un signe de ponctuation par exemple. Nous utilisons le terme \"approximatif\" parce que la fonction `split()` transforme une chaîne de caractères en liste en considérant par défaut le caractère espace. En d'autres termes, le nombre exact de tokens est plus élevé puisque les signes de ponctuation peuvent être collés aux mots.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utiliser le *pipeline* de traitement de CLTK"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CLTK est spécialement conçu pour le traitement de langues naturelles appliqué aux langues antiques et médiévales. Pour utiliser au mieux cette bibliothèque, nous avons d'abord besoin d'importer le *pipeline* mentionné."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cltk import NLP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si le code ci-dessus a fonctionné sans générer d'erreur, alors cela signifie que nous avons correctement importé la classe NLP depuis CLTK. Cela nous permet de créer un *pipeline* de traitement de CLTK. Pour ce faire, nous avons cependant besoin de connaître la langue dans laquelle le texte a été écrit. Tite-Live était un auteur romain, la langue est donc le latin et son code est \"lat\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Charger le pipline par défaut du latin\n",
    "cltk_nlp = NLP(language=\"lat\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`NLP(language=\"lat\")` est une variable qui contient le *pipeline* de traitement par défaut proposé par CLTK pour le latin. Il est possible de définir son propre *pipeline* de traitement. Il est courant d'utiliser une variable qui contient le nom `nlp` pour se rappeler facilement qu'on manipule un *pipeline* de traitement.\n",
    "\n",
    "La sortie de cette cellule fournit des informations clés sur notre *pipeline*. Ça inclut les différents *pipelines* de traitement,\n",
    "ou processus appliqués aux données d'entrée (le texte) :\n",
    "- `LatinNormalizeProcess`\n",
    "- `LatinStanzaProcess`\n",
    "- `LatinEmbeddingsProcess`\n",
    "- `StopsProcess`\n",
    "- `LatinNERProcess`\n",
    "- `LatinLexiconProcess`\n",
    "\n",
    "Nous allons étudier chacun de processus ou *process* en profondeur dans ce *notebook*. Pour le moment, il suffit de comprendre qu'un *pipeline* de traitement est une suite ordonnée de processus. L'entrée du *pipeline* s'applique à du texte et la sortie est un document `Doc` propre à CLTK. Un processus se situant après un autre processus peut en dépendre, l'ordre est donc important.\n",
    "Nous allons aborder l'ensemble des processus plus tard dans ce *notebook*. Pour l'instant, il faut comprendre que le texte qui est passé par une instance de la classe NLP passe à travers un certain nombre de processus dans le *pipeline*. L'ordre est important à respecter puisque des processus dépendent du résultat des processus précédents.\n",
    "\n",
    "Si on veut enlever un processus du *pipeline* de traitements, on peut modifier directement l'attribut `cltk_nlp.pipeline.processes` en appliquant la méthode `pop()`. Si aucun argument n'est donné, alors le dernier élément est retiré. S'il y a un argument, alors c'est l'indice de l'élément dans la liste à retirer.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cltk_nlp.pipeline.processes.pop()\n",
    "print(cltk_nlp.pipeline.processes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Une raison de retirer un processus peut être de vouloir éviter des traitements trop long. Le processus `LatinLexiconProcess` prend beaucoup de temps et ne correspond pas forcément à tous les besoins, comme le nôtre qui est de faire un *pipeline* de traitements pour trouver les entités nommées dans des textes.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The CLTK Doc Object"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Maintenant que nous avons mis en place notre *pipeline*, analysons un texte. Pour ce faire, nous allons créer un objet CLTK Doc. Si vous êtes déjà familié avec spaCy ou d'autres bibliothèques de TAL, ça doit vous dire quelque chose. L'objet Doc contient les données du texte. Avant que nous examinions l'objet `Doc`, instancions en donc un. Tout d'abord, raccourcissons le texte de Tite-Live.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "livy = livy_full[:len(livy_full) // 12]\n",
    "print(\"Nombre approximatif de tokens :\", len(livy.split()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Une fois le texte raccourci, créons un objet `Doc` en appelant la méthode `analyze()` de `cltk_doc` avec comme premier argument le texte à analyser. Si c'est la première fois que vous exécutez ce code, le code va vous demander d'entrer \"Y\" pour télécharger les modèles."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cltk_doc = cltk_nlp.analyze(text=livy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Une fois les modèles téléchargés, notre *pipeline* de traitements exécute les processus à partir du texte. Commençons par examiner l'objet `Doc` généré."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(cltk_doc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "C'est une classe définie par le code de CLTK. Ça ne fait pas partie du code de base de Python."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Les accesseurs de l'objet Doc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'objet `Doc` a des variables que l'on appelle attributs ou propriétés, selon qu'elles sont directement enregistrées comme telles (attributs) ou calculéss à partir d'attributs (propriétés). On regroupe les attributs et les propriétés sous le terme d'accesseurs (ou *accessors* en anglais). Dans notre cas, ces accesseurs, seront ou biende type de base de Python ou bien seront composés d'objets propres à CLTK comme `Word` par exemple. Ces accesseurs nous aideront à parser de différentes manières, à notre guise, les variables de type `Doc`.\n",
    "\n",
    "Regardons d'abord les accesseurs directement disponibles à partir d'une variable `Doc`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accessors = ([x for x in dir(cltk_doc) if not x.startswith(\"__\")])\n",
    "for a in accessors:\n",
    "    print (a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examinons plusieurs de ces accesseurs en détail. Chaque accesseur a un titre de telle manière qu'il vous est possible de naviguer facilement entre les paragraphes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'attribut `raw` (cru, brut en anglais) est le texte brut que l'on a donné en entré du *pipeline*."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (cltk_doc.raw[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'attribut *tokens* est une liste ordonnée qui contient les tokens du texte."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(cltk_doc.tokens[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vous pouvez voir que les tokens sont isolés les uns par rapport aux autres dans une liste. Les mots et la ponctuation ont chacun leur place. Une étude du texte au niveau des mots est dès lors possible."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lemmata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comme la propriété `tokens`, la propriété `lemmata` est aussi une liste dérivée du texte brut à la différence près que les éléments sont les lemmes associés aux tokens. Un lemme est la forme du dictionnaire associé à un token. Ici, on a le token \"capta\" qui est associé au lemme \"capio\" parce qu'en latin, la forme du dictionnaire d'un participe passé est la première personne du singulier du présent de l'indicatif du verbe en question."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(cltk_doc.lemmata[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### POS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La propriété `pos` fonctionne de la même manière, mais contient la nature du mot en lieu et place du token dans `tokens`. `pos` est l'acronyme de *part-of-speech* ou *pars oratori* en latin qui correspond au français \"nature du mot\" ou \"nature grammaticale\". Cet attribut est très courant dans les bibliothèques de TAL."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(cltk_doc.pos[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La propriété `words` est aussi une liste comme `tokens` ou `lemmata` mais elle ne contient pas de *strings* mais contient des objets de type `Word`. Regardons le septième élements de `words`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (cltk_doc.words[6])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "C'est un objet qui a lui-même plusieurs accesseurs ! Nous pouvons voir toutes les données pertinentes à l'échelle d'un mot. On peut voir quelle est la nature du mot sélectionné."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (cltk_doc.words[6].pos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Maintenant que nous savons que c'est un verbe, on peut vouloir connaître sa voix (voix active ou voix passive). On regarde pour ça l'attribut `features` qui est un dictionnaire."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (cltk_doc.words[6].features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le dictionnaire a une clef \"Voice\" qui est associée à la valeur \"passive\". Ce verbe est à la voix passive !"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (cltk_doc.words[6].features[\"Voice\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut voir les autres élements facilement."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Number:\", cltk_doc.words[6].features[\"Number\"])\n",
    "print(\"Tense:\", cltk_doc.words[6].features[\"Tense\"])\n",
    "print(\"VerbForm:\", cltk_doc.words[6].features[\"VerbForm\"]) \n",
    "print(\"Voice:\", cltk_doc.words[6].features[\"Voice\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Je vous encourage à prendre le temps de découvrir les possibilités offertes par les classes `Doc` et `Word` et leurs accesseurs. Grâce à elles, vous pouvez aisément profiter de toute la puissance de CLTK. En prime, il est possible d'ajouter autant d'accesseurs que nécessaires."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentence Tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Contrairement aux attributs précédents, `sentence_tokens` nous permet d'analyser le texte au niveau de la phrase. Ainsi, le parsage phrase par phrase devient possible. L'approche la plus simple pour séparer les phrases est d'utiliser `split(\".\")`. Cependant, cette méthode est très imprécise parce que les points peuvent noter des abbréviations en plein milieu d'une phrase par exemple. Grâce aux fonctions *ad hoc* écrites par CLTK, on peut séparer aisément les phrases d'un texte en latin."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "floral-antique",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f5782-9752-48f7-bba5-538a8f627954",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ce chapitre a présenté les principales caractéristiques de la class NLP et nous avons vu comment construire le *pipeline* de traitement et comment y passer un texte à travers lui. Dans le prochain chapitre, nous allons examiner plus particulièrement la reconnaissance d'entités nommées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76567c-bac9-48c8-ba9f-5acfa726df2c",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}